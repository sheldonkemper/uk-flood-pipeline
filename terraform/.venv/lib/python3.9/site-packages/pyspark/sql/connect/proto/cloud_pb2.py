#
# DATABRICKS CONFIDENTIAL & PROPRIETARY
# __________________
#
# Copyright 2023-present Databricks, Inc.
# All Rights Reserved.
#
# NOTICE:  All information contained herein is, and remains the property of Databricks, Inc.
# and its suppliers, if any.  The intellectual and technical concepts contained herein are
# proprietary to Databricks, Inc. and its suppliers and may be covered by U.S. and foreign Patents,
# patents in process, and are protected by trade secret and/or copyright law. Dissemination, use,
# or reproduction of this information is strictly forbidden unless prior written permission is
# obtained from Databricks, Inc.
#
# If you view or obtain a copy of this information and believe Databricks, Inc. may not have
# intended it to be made available, please promptly report it to Databricks Legal Department
# @ legal@databricks.com.
#
# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: spark/connect/cloud.proto
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database

# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
    b'\n\x19spark/connect/cloud.proto\x12\rspark.connect"\x85\x01\n\rResultOptions\x12\x35\n\x04type\x18\x01 \x01(\x0e\x32!.spark.connect.ResultOptions.TypeR\x04type"=\n\x04Type\x12\x14\n\x10TYPE_UNSPECIFIED\x10\x00\x12\x0f\n\x0bTYPE_INLINE\x10\x01\x12\x0e\n\nTYPE_CLOUD\x10\x02"\xe4\x01\n\x10\x43loudResultBatch\x12@\n\x07results\x18\x01 \x03(\x0b\x32&.spark.connect.CloudResultBatch.ResultR\x07results\x1a\x8d\x01\n\x06Result\x12\x10\n\x03url\x18\x02 \x01(\tR\x03url\x12\x1b\n\trow_count\x18\x03 \x01(\x03R\x08rowCount\x12\'\n\x0f\x63ompressed_size\x18\x04 \x01(\x03R\x0e\x63ompressedSize\x12+\n\x11uncompressed_size\x18\x05 \x01(\x03R\x10uncompressedSizeB"\n\x1eorg.apache.spark.connect.protoP\x01\x62\x06proto3'
)


_RESULTOPTIONS = DESCRIPTOR.message_types_by_name["ResultOptions"]
_CLOUDRESULTBATCH = DESCRIPTOR.message_types_by_name["CloudResultBatch"]
_CLOUDRESULTBATCH_RESULT = _CLOUDRESULTBATCH.nested_types_by_name["Result"]
_RESULTOPTIONS_TYPE = _RESULTOPTIONS.enum_types_by_name["Type"]
ResultOptions = _reflection.GeneratedProtocolMessageType(
    "ResultOptions",
    (_message.Message,),
    {
        "DESCRIPTOR": _RESULTOPTIONS,
        "__module__": "spark.connect.cloud_pb2"
        # @@protoc_insertion_point(class_scope:spark.connect.ResultOptions)
    },
)
_sym_db.RegisterMessage(ResultOptions)

CloudResultBatch = _reflection.GeneratedProtocolMessageType(
    "CloudResultBatch",
    (_message.Message,),
    {
        "Result": _reflection.GeneratedProtocolMessageType(
            "Result",
            (_message.Message,),
            {
                "DESCRIPTOR": _CLOUDRESULTBATCH_RESULT,
                "__module__": "spark.connect.cloud_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.CloudResultBatch.Result)
            },
        ),
        "DESCRIPTOR": _CLOUDRESULTBATCH,
        "__module__": "spark.connect.cloud_pb2"
        # @@protoc_insertion_point(class_scope:spark.connect.CloudResultBatch)
    },
)
_sym_db.RegisterMessage(CloudResultBatch)
_sym_db.RegisterMessage(CloudResultBatch.Result)

if _descriptor._USE_C_DESCRIPTORS == False:

    DESCRIPTOR._options = None
    DESCRIPTOR._serialized_options = b"\n\036org.apache.spark.connect.protoP\001"
    _RESULTOPTIONS._serialized_start = 45
    _RESULTOPTIONS._serialized_end = 178
    _RESULTOPTIONS_TYPE._serialized_start = 117
    _RESULTOPTIONS_TYPE._serialized_end = 178
    _CLOUDRESULTBATCH._serialized_start = 181
    _CLOUDRESULTBATCH._serialized_end = 409
    _CLOUDRESULTBATCH_RESULT._serialized_start = 268
    _CLOUDRESULTBATCH_RESULT._serialized_end = 409
# @@protoc_insertion_point(module_scope)
